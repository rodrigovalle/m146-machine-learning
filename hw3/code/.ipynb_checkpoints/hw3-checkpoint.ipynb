{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, Math\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from src.twitter import extract_words, read_vector_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Implement `extract_dictionary(...)` that uses `extract_words(...)` to read all unique words contained in a file into a dictionary. Process the tweets in the order they appear in the file to create this dictionary of $d$ unique words/punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dictionary(infile):\n",
    "    \"\"\"\n",
    "    Given a filename, reads the text file and builds a dictionary of\n",
    "    unique words/punctuations.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        infile -- string, filename\n",
    "    Returns\n",
    "    ----------\n",
    "        word_list -- dictionary, (key, value) pairs are\n",
    "                     (word, index)\n",
    "    \"\"\"\n",
    "    with open(infile, 'r') as fid:\n",
    "        unique_words = set(extract_words(fid.read()))\n",
    "        return {word: i for i, word in enumerate(unique_words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Next, implement `extract_feature_vectors(...)` that produces the bag-of-words representation of a file based on the extracted dictionary. That is, for each tweet $i$, construct a feature vector of length $d$, where the $j^{\\text{th}}$ entry in the feature vectors is 1 if the $j^{\\text{th}}$ word in the dictionary is present in tweet $i$, or 0 otherwise. For $n$ tweets, save the feature vectors in a feature matrix, where the rows correspond to tweets (examples) and the columns correspond to words (features). Maintain the order of the tweets as they appear in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_vectors(infile, word_list):\n",
    "    \"\"\"\n",
    "    Produces a bag-of-words representation of a text file specified\n",
    "    by the filename infile based on the dictionary word_list.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        infile -- string, filename\n",
    "        world_list -- dictionary, (key, value) pairs are\n",
    "                      (word, index)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "        feature_matrix -- numpy array of shape (n,d)\n",
    "                          boolean (0,1) array indicating words\n",
    "                          presence in a string\n",
    "\n",
    "    \"\"\"\n",
    "    num_lines = sum(1 for line in open(infile, 'r'))\n",
    "    num_words = len(word_list)\n",
    "    feature_matrix = np.zeros((num_lines, num_words))\n",
    "    \n",
    "    with open(infile, 'r') as fid:\n",
    "        for j, tweet in enumerate(fid):\n",
    "            for word in extract_words(tweet):\n",
    "                i = word_list[word]\n",
    "                feature_matrix[j][i] = 1\n",
    "                \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'data/tweets.txt'\n",
    "dictionary = extract_dictionary(data_file)\n",
    "X = extract_feature_vectors(data_file, dictionary)\n",
    "y = read_vector_file('data/labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>1805</th>\n",
       "      <th>1806</th>\n",
       "      <th>1807</th>\n",
       "      <th>1808</th>\n",
       "      <th>1809</th>\n",
       "      <th>1810</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>630 rows × 1811 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     ...   1805  1806  1807  1808  1809  \\\n",
       "0     0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "1     0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "2     0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "3     0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "4     0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "5     0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   1.0   0.0   \n",
       "..    ...   ...   ...   ...   ...   ...  ...    ...   ...   ...   ...   ...   \n",
       "624   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "625   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "626   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "627   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "628   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "629   0.0   0.0   0.0   0.0   0.0   0.0  ...    0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "     1810  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  \n",
       "..    ...  \n",
       "624   0.0  \n",
       "625   0.0  \n",
       "626   0.0  \n",
       "627   0.0  \n",
       "628   0.0  \n",
       "629   0.0  \n",
       "\n",
       "[630 rows x 1811 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 12\n",
    "pd.options.display.max_columns = 12\n",
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012, Micheal:This Is it && A Christmas Carol Are Cool Movies\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(1.0, 'this'),\n",
       " (1.0, 'movies'),\n",
       " (1.0, 'micheal'),\n",
       " (1.0, 'it'),\n",
       " (1.0, 'is'),\n",
       " (1.0, 'cool'),\n",
       " (1.0, 'christmas'),\n",
       " (1.0, 'carol'),\n",
       " (1.0, 'are'),\n",
       " (1.0, 'a'),\n",
       " (1.0, ':'),\n",
       " (1.0, '2012'),\n",
       " (1.0, ','),\n",
       " (1.0, '&'),\n",
       " (0.0, '|'),\n",
       " (0.0, 'zigster'),\n",
       " (0.0, 'z'),\n",
       " (0.0, 'yumm'),\n",
       " (0.0, 'your'),\n",
       " (0.0, 'you')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1811"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(data_file, 'r') as f:\n",
    "    display(next(f))\n",
    "feature_vec = sorted(zip(X[0], dictionary.keys()), reverse=True)\n",
    "display(feature_vec[:20], len(feature_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Split the feature matrix and corresponding labels into your training and test sets. **The first 560 tweets will be used for training and the last 70 tweets will be used for testing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# note: the data is being shuffled implicitly by train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=560)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Indicate that you have finished the feature extraction and generated the train/test splits in your write-up. ✓"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Hyper-parameter Selection for a Linear-Kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) The result of a hyperparameter selection often depends upon the choice of performance measure. Here, we will consider the following performance measures: **accuracy**, **F1-score**, and **AUROC**.\n",
    "\n",
    "Implement `performance(...)`. All measures are implemented in `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(y_true, y_pred, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Calculates the performance metric based on the agreement between\n",
    "    the true labels and the predicted labels.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        y_true -- numpy array of shape (n,), known labels\n",
    "        y_pred -- numpy array of shape (n,), (continuous-valued)\n",
    "                  predictions\n",
    "        metric -- string, option used to select the performance\n",
    "                  measure\n",
    "                  options: 'accuracy', 'f1-score', 'auroc'\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        score  -- float, performance score\n",
    "    \"\"\"\n",
    "    # map continuous-valued predictions to binary labels\n",
    "    y_label = np.sign(y_pred)\n",
    "    y_label[y_label==0] = 1\n",
    "    \n",
    "    scorer = {\n",
    "        'accuracy': metrics.accuracy_score,\n",
    "        'f1_score': metrics.f1_score,\n",
    "        'auroc': metrics.roc_auc_score,\n",
    "    }[metric]\n",
    "    \n",
    "    return scorer(y_true, y_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "(b) Next, implement `cv_performance(...)` to return the mean $k$-fold CV performance for the performance metric passed into the function. Here, you will make use of `SVC.fit(X,y)` and the `SVC.decision_function(X)`, as well as your `performance(...)` function.\n",
    "\n",
    "You may have noticed that the proportion of the two classes (positive and negative) are not equal in the training data. When dividing the data into folds for CV, you should try to keep the class proportions roughly the same across folds. In your write-up briefly describe why it might be beneficial to maintain class proportions across folds. Then, use `sklearn.cross_validation.StratifiedKFold(...)` to split the data for 5-fold CV, making sure to stratify using only the training labels.\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "We would want to try to keep class proportions the same across folds to avoid oversampling any one class accidentally. If this were to happen, we might choose a set of examples of all the same class for example. In this scenario, even a trivial classifier that always predicts the majority class can get 100% training accuracy (but will probably have horrible test accuracy because its not a very expressive model). Essentially, it's impossible to learn the class separation when there's an overwhelming majority of a single class, so we use stratified sampling to avoid this situation and keep similar class distributions between the whole data set and any sampled training sets.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_performance(clf, X, y, kf, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Splits the data, X and y, into k-folds and runs k-fold\n",
    "    cross-validation. Trains classifier on k-1 folds and tests on the\n",
    "    remaining fold. Calculates the k-fold cross-validation\n",
    "    performance metric for classifier by averaging the performance\n",
    "    across folds.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf    -- classifier (instance of SVC)\n",
    "        X      -- numpy array of shape (n,d), feature vectors\n",
    "                    n = number of examples\n",
    "                    d = number of features\n",
    "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
    "        kf     -- cross_validation.KFold or\n",
    "                  cross_validation.StratifiedKFold\n",
    "        metric -- string, option used to select performance measure\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        score   -- float, average cross-validation performance across\n",
    "                   k folds\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X, y):\n",
    "        X_train_fold, X_test_fold = X[train_index], X[test_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[test_index]\n",
    "        \n",
    "        svm = clf.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = svm.decision_function(X_test_fold)\n",
    "        scores.append(performance(y_test_fold, y_pred, metric=metric))\n",
    "        \n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6535764114303937"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_performance(SVC(gamma='auto'), X_train, y_train, StratifiedKFold(n_splits=5), metric='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Now, implement `select_param_linear(...)` to choose a setting for $C$ for a linear SVM based on the training data and the specified metric. Your function should call `cv_performance(...)`, passing in instances of `SVC(kernel='linear', C=c)` with different values for `C`, e.g. $C = 10^{-3}, 10^{-2}, 10^{-1}, 1, 10, 10^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_param_linear_helper(c_range, X, y, kf, metric='accuracy'):\n",
    "    return {\n",
    "        c:\n",
    "        cv_performance(\n",
    "            SVC(kernel='linear', C=c, gamma='auto'),\n",
    "            X, y, kf, metric=metric\n",
    "        )\n",
    "        for c in c_range\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_param_linear(X, y, kf, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Sweeps different settings for the hyperparameter of a linear-\n",
    "    kernel SVM, calculating the k-fold CV performance for each\n",
    "    setting, then selecting the hyperparameter that 'maximize'\n",
    "    the average k-fold CV performance.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        X      -- numpy array of shape (n,d), feature vectors\n",
    "                    n = number of examples\n",
    "                    d = number of features\n",
    "        y      -- numpy array of shape (n,), binary labels {1,-1}\n",
    "        kf     -- cross_validation.KFold or\n",
    "                  cross_validation.StratifiedKFold\n",
    "        metric -- string, option used to select performance measure\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        C -- float, optimal parameter value for linear-kernel SVM\n",
    "    \"\"\"\n",
    "\n",
    "    print('Linear SVM Hyperparameter Selection based on ' + str(metric) + ':')\n",
    "    c_range = 10.0 ** np.arange(-3, 3)\n",
    "    results = select_param_linear_helper(c_range, X, y, kf, c_range, metric=metric)\n",
    "    return c_range[np.argmax(results)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Finally, using the training data from Section 4.1 and the functions implemented here, find the best setting for $C$ for each performance measure mentioned above. Report your findings in tabular format (up to the fourth decimal place)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_range = 10.0 ** np.arange(-3, 3)\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "scores = {\n",
    "    metric: select_param_linear_helper(\n",
    "        c_range,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        kf,\n",
    "        metric=metric,\n",
    "    )\n",
    "    for metric in ['accuracy', 'f1_score', 'auroc']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>C</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.001</th>\n",
       "      <td>0.6536</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.01</th>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.8497</td>\n",
       "      <td>0.7109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.8072</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>0.7688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.7953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.0</th>\n",
       "      <td>0.8196</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.7953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best C</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "C       accuracy  f1_score   auroc\n",
       "0.001     0.6536    0.7905  0.5000\n",
       "0.01      0.7822    0.8497  0.7109\n",
       "0.1       0.8072    0.8584  0.7688\n",
       "1.0       0.8250    0.8675  0.8019\n",
       "10.0      0.8196    0.8636  0.7953\n",
       "100.0     0.8196    0.8636  0.7953\n",
       "best C    1.0000    1.0000  1.0000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=scores)\n",
    "df = df.rename_axis('C', axis='columns')\n",
    "df.append(df.idxmax().rename('best C')).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your `select_param_linear(...)` function returns the 'best' $C$ given a range of values. How does the 5-fold CV performance vary with $C$ and the performance metric?\n",
    "\n",
    "<span style=\"color:blue\">\n",
    "In general, it seems that AUROC is the most pessimistic metric of the three, F1 is optimistic, and accuracy is middle-of-the-road.\n",
    "</span>\n",
    "\n",
    "<span style=\"color:blue\"> \n",
    "For lower values of $C$, i.e. $C < 1$, the accuracy of the SVM across all performance metrics grows worse as $C$ decreases. For $C > 1$, we note that the performance seems to level off across all performance metrics as the SVM becomes less willing to provide slack and penalizes misclassified examples more harshly. Performance peaks at $C = 1$ for all metrics because $C = 1$ is the choice for this dataset where enough slack is afforded to account for any outlier examples while still maintaining a hard enough margin to accurately separate all other data.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(ncols=1)\n",
    "\n",
    "ax.set_ylabel('$C$')\n",
    "ax.set_xticklabels(['', 'accuracy', 'f1_score', 'auroc'], rotation=35, ha='left')\n",
    "ax.set_yticklabels(['']  + list(map(str, c_range)))\n",
    "im = ax.matshow(df)\n",
    "fig.colorbar(im, ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Test Set Performance\n",
    "(a) Based on the results you obtained in Section 4.2, choose a hyperparameter setting for the linear-kernel SVM. Then, using the training data extracted in Section 4.1 and `SVC.fit(...)`, train a linear-kernel SVM with your chosen settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', gamma='auto', C=1.0)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Implement `performance_test(...)` which returns the value of a performance measure, given the test data and a trained classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_test(clf, X, y, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Estimates the performance of the classifier using the 95% CI.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf    -- classifier (instance of SVC) [already fit to data]\n",
    "        X      -- numpy array of shape (n,d), feature vectors of test\n",
    "                  set\n",
    "                    n = number of examples\n",
    "                    d = number of features\n",
    "        y      -- numpy array of shape (n,), binary labels {1,-1} of\n",
    "                  test set\n",
    "        metric -- string, option used to select performance measure\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        score  -- float, classifier performance\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = clf.decision_function(X)\n",
    "    return performance(y, y_pred, metric=metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) For each performance metric, use `performance_test(...)` and the trained linear-kernel SVM classifier to measure performance on the test data. Report the results. Be sure to include the name of the performance metric employed and the performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_scores = {\n",
    "    metric: performance_test(clf, X_test, y_test, metric=metric)\n",
    "    for metric in ['accuracy', 'f1_score', 'auroc']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>performance:</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.849359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              accuracy  f1_score     auroc\n",
       "performance:  0.857143       0.9  0.849359"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(performance_scores, index=['performance:'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: training data has been shuffled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
